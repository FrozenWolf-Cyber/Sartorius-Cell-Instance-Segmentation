{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T02:20:53.048499Z",
     "iopub.status.busy": "2021-10-22T02:20:53.047964Z",
     "iopub.status.idle": "2021-10-22T02:20:55.442888Z",
     "shell.execute_reply": "2021-10-22T02:20:55.442186Z",
     "shell.execute_reply.started": "2021-10-22T02:20:53.048407Z"
    }
   },
   "source": [
    "## **Contents**\n",
    "-  [Introduction](#i)\n",
    "-  [1.Importing Libraries](#1)\n",
    "-  [2.Helper Functions](#2)\n",
    "-  [3.Dataset Managament](#3)\n",
    "    -  [3.1.Dataset and DataLoaders](#3.1)\n",
    "    -  [3.2.Visualizing Dataset](#3.2)\n",
    "-  [4.Initializing pre-trained model](#4)\n",
    "-  [5.Training](#5)\n",
    "-  [6.Plotting Graphs](#6)\n",
    "    -  [6.1.Plotting Loss vs MiniBatch](#6.1)\n",
    "    -  [6.2.Plotting Loss vs Epoch](#6.2)\n",
    "-  [7.Loading and Testing](#7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction** <a class=\"anchor\" id=\"i\"></a>\n",
    "\n",
    "\n",
    "In this notebook I am visualizing the dataset and also fine-tuning pre-trained [Mask-RCNN](https://arxiv.org/abs/1703.06870) model using [Pytorch](https://pytorch.org/) library.Mask R-CNN is a popular deep learning instance segmentation technique that performs pixel-level segmentation on detected objects.\n",
    "\n",
    "The Mask R-CNN algorithm can accommodate multiple classes and overlapping objects.Mask R-CNN extends Faster R-CNN to solve instance segmentation tasks. It achieves this by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. In principle, Mask R-CNN is an intuitive extension of Faster R-CNN, but constructing the mask branch properly is critical for good results. \n",
    "\n",
    "Instance segmentation treats multiple objects of the same class as distinct individual instances which give this model slight advantage over other Semantic segmentation models. \n",
    "\n",
    "\n",
    "Read more about Mask-RCNN [here](https://www.analyticsvidhya.com/blog/2019/07/computer-vision-implementing-mask-r-cnn-image-segmentation/)\n",
    "\n",
    "Some of the helper functions and dataloader classes are the derivatives of [this](https://www.kaggle.com/julian3833/sartorius-starter-torch-mask-r-cnn-lb-0-173#%F0%9F%A6%A0-Sartorius---Starter-Torch-Mask-R-CNN) notebook.\n",
    "\n",
    "<img src= \"attachment:e21e8027-d32b-49eb-8685-18e763bda774.png\"  style='width: 800px;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.Importing Libraries** <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:54:27.498180Z",
     "iopub.status.busy": "2021-10-22T12:54:27.497438Z",
     "iopub.status.idle": "2021-10-22T12:54:27.507161Z",
     "shell.execute_reply": "2021-10-22T12:54:27.506241Z",
     "shell.execute_reply.started": "2021-10-22T12:54:27.498140Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from PIL import Image\n",
    "from sklearn import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset as Dataset\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "sys.path.append(\"../input/maskrcnn-utils/\")\n",
    "from transforms import ToTensor, RandomHorizontalFlip, Compose\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.Helper Functions** <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:54:27.536881Z",
     "iopub.status.busy": "2021-10-22T12:54:27.536602Z",
     "iopub.status.idle": "2021-10-22T12:54:27.557120Z",
     "shell.execute_reply": "2021-10-22T12:54:27.556129Z",
     "shell.execute_reply.started": "2021-10-22T12:54:27.536853Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_W ,IMG_H = 520, 704\n",
    "root = \"../input/sartorius-cell-instance-segmentation/\"\n",
    "\n",
    "def rle_decode(mask_rle, shape, color=1):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    \n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = color\n",
    "    return img.reshape(shape)\n",
    "\n",
    "def test_model(model, dataloader,n):\n",
    "    \n",
    "    for i in range(n):\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        img, targets = next(iter(dataloader))\n",
    "        img = img[0]\n",
    "        targets = targets[0]\n",
    "        plt.imshow(img.numpy().transpose((1,2,0)))\n",
    "        plt.grid(None)\n",
    "        plt.title(f\"Image : {i}\")\n",
    "        plt.show()\n",
    "    \n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        all_masks = np.zeros((IMG_W ,IMG_H))\n",
    "        for mask in targets['masks']:\n",
    "            all_masks = np.logical_or(all_masks, mask)\n",
    "        plt.imshow(img.numpy().transpose((1,2,0)))\n",
    "        plt.imshow(all_masks, alpha=0.3)\n",
    "        plt.grid(None)\n",
    "        plt.title(f\"Target : {i}\")\n",
    "        plt.show()\n",
    "    \n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model([img.to(device)])[0]\n",
    "\n",
    "        plt.imshow(img.cpu().numpy().transpose((1,2,0)))\n",
    "        all_preds_masks = np.zeros((IMG_W ,IMG_H))\n",
    "        for mask in preds['masks'].cpu().detach().numpy():\n",
    "            all_preds_masks = np.logical_or(all_preds_masks, mask[0])\n",
    "        plt.imshow(all_preds_masks, alpha=0.4)\n",
    "        plt.grid(None)\n",
    "        plt.title(f\"Predictions : {i}\")\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "# Stolen from: https://www.kaggle.com/arunamenon/cell-instance-segmentation-unet-eda\n",
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "# Modified by me\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return ' '.join(map(str, run_lengths))\n",
    "\n",
    "\n",
    "def does_overlap(mask, other_masks):\n",
    "    for other_mask in other_masks:\n",
    "        if np.sum(np.logical_and(mask, other_mask)) > 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def remove_overlapping_pixels(mask, other_masks):\n",
    "    for other_mask in other_masks:\n",
    "        if np.sum(np.logical_and(mask, other_mask)) > 0:\n",
    "            mask[np.logical_and(mask, other_mask)] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.Dataset Managament** <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Downloading and Extracting Dataset <a class=\"anchor\" id=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:54:27.559471Z",
     "iopub.status.busy": "2021-10-22T12:54:27.559155Z",
     "iopub.status.idle": "2021-10-22T12:54:28.428938Z",
     "shell.execute_reply": "2021-10-22T12:54:28.428225Z",
     "shell.execute_reply.started": "2021-10-22T12:54:27.559398Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SatoriusDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transforms, root = 'data/',train = True):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.w , self.h = 520 , 704\n",
    "        info = pd.read_csv(self.root+'train.csv')[[\"id\",\"annotation\"]]\n",
    "        info = info.groupby('id')['annotation'].agg(lambda x: list(x)).reset_index()\n",
    "        validation =  30\n",
    "        self.data_info = 0\n",
    "\n",
    "        if train == True:\n",
    "            self.data_info = info[validation:].reset_index(drop=True)\n",
    "        else:\n",
    "            self.data_info = info[:validation].reset_index(drop=True)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.root+'train/'+self.data_info['id'][idx]+'.png').convert(\"RGB\")\n",
    "        mask = np.zeros((len(self.data_info['annotation'][idx]), self.w, self.h), dtype=int)\n",
    "        \n",
    "        num_objs = len(self.data_info['annotation'][idx])\n",
    "        \n",
    "        for i in range(num_objs):\n",
    "            nth_mask = rle_decode(self.data_info['annotation'][idx][i], (self.w, self.h))\n",
    "            nth_mask = np.array(nth_mask) > 0\n",
    "            mask[i, :, :] = nth_mask\n",
    "    \n",
    "\n",
    "        \n",
    "        boxes = []\n",
    "        new_masks = []\n",
    "\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(mask[i, :, :])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            new_masks.append(mask[i, :, :])\n",
    "        \n",
    "        nmx = np.zeros((num_objs ,self.w, self.h), dtype=int)\n",
    "        \n",
    "        for i in range(num_objs):\n",
    "            nmx[i, :, :] = new_masks[i]\n",
    "        \n",
    "            \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(nmx, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img,target = self.transforms(img,target)\n",
    "            \n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "\n",
    "    \n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(ToTensor())\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(RandomHorizontalFlip(0.5))\n",
    "    return Compose(transforms)\n",
    "\n",
    "\n",
    "train_dataset = SatoriusDataset(transforms=get_transform(train=True),root =root,train = True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "validation_dataset = SatoriusDataset(transforms=get_transform(train=False),root =root,train = False)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Visualizing Dataset <a class=\"anchor\" id=\"3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:54:28.430639Z",
     "iopub.status.busy": "2021-10-22T12:54:28.430394Z",
     "iopub.status.idle": "2021-10-22T12:54:28.477123Z",
     "shell.execute_reply": "2021-10-22T12:54:28.476467Z",
     "shell.execute_reply.started": "2021-10-22T12:54:28.430608Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_dataset.data_info\n",
    "validation_df = validation_dataset.data_info\n",
    "\n",
    "pd.set_option('max_colwidth', 125)\n",
    "display(train_df.head())\n",
    "display(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:54:28.478959Z",
     "iopub.status.busy": "2021-10-22T12:54:28.478513Z",
     "iopub.status.idle": "2021-10-22T12:54:29.158010Z",
     "shell.execute_reply": "2021-10-22T12:54:29.157050Z",
     "shell.execute_reply.started": "2021-10-22T12:54:28.478924Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_palette(\"pastel\")\n",
    "\n",
    "n_annotations = [[],[]] #[[train], [validation]]\n",
    "for i in train_df['annotation']:\n",
    "    n_annotations[0].append(len(i))\n",
    "    \n",
    "for i in validation_df['annotation']:\n",
    "    n_annotations[1].append(len(i))\n",
    "\n",
    "x_axis,y_axis = 'Number Of Annotations' , 'Number Of Images'\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "p = sns.histplot(data = n_annotations[0])\n",
    "p.set_xlabel(x_axis, fontsize = 15)\n",
    "p.set_ylabel(y_axis, fontsize = 15)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "p = sns.histplot(data = n_annotations[1])\n",
    "p.set_xlabel(x_axis, fontsize = 15)\n",
    "p.set_ylabel(x_axis, fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:54:29.160733Z",
     "iopub.status.busy": "2021-10-22T12:54:29.160459Z",
     "iopub.status.idle": "2021-10-22T12:54:33.214776Z",
     "shell.execute_reply": "2021-10-22T12:54:33.214154Z",
     "shell.execute_reply.started": "2021-10-22T12:54:29.160696Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img, targets = next(iter(validation_dataloader))\n",
    "image = np.array(img[0])\n",
    "targets = targets[0]\n",
    "image = cv2.cvtColor(image.transpose((1,2,0)), cv2.COLOR_BGR2RGB)\n",
    "all_masks = np.zeros((IMG_W ,IMG_H))\n",
    "for mask in targets['masks']:\n",
    "    all_masks = np.logical_or(all_masks, mask)\n",
    "    \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.imshow(all_masks, alpha=0.5)\n",
    "plt.axis(\"off\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(all_masks)\n",
    "plt.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:54:33.216580Z",
     "iopub.status.busy": "2021-10-22T12:54:33.216142Z",
     "iopub.status.idle": "2021-10-22T12:54:42.167662Z",
     "shell.execute_reply": "2021-10-22T12:54:42.166218Z",
     "shell.execute_reply.started": "2021-10-22T12:54:33.216545Z"
    }
   },
   "outputs": [],
   "source": [
    "def clustered_img(x):\n",
    "    kmeans = cluster.KMeans(2)\n",
    "    dims = np.shape(x)\n",
    "    pixel_matrix = np.reshape(x, (dims[0] * dims[1], dims[2]))\n",
    "    clustered = kmeans.fit_predict(pixel_matrix)\n",
    "    clustered_img = np.reshape(clustered, (dims[0], dims[1]))\n",
    "    return clustered_img\n",
    "\n",
    "for i in range(2):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    img, targets = next(iter(validation_dataloader))\n",
    "    img = img[0]\n",
    "    targets = targets[0]\n",
    "    plt.imshow(clustered_img(img.numpy().transpose((1,2,0))))\n",
    "    plt.grid(None)\n",
    "    plt.title(\"K-Means\")\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    all_masks = np.zeros((IMG_W ,IMG_H))\n",
    "    for mask in targets['masks']:\n",
    "        all_masks = np.logical_or(all_masks, mask)\n",
    "    plt.imshow(img.numpy().transpose((1,2,0)))\n",
    "    plt.imshow(all_masks, alpha=0.3)\n",
    "    plt.grid(None)\n",
    "    plt.title(\"Target\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.Initializing pre-trained model** <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:54:42.169546Z",
     "iopub.status.busy": "2021-10-22T12:54:42.169080Z",
     "iopub.status.idle": "2021-10-22T12:54:42.176031Z",
     "shell.execute_reply": "2021-10-22T12:54:42.175038Z",
     "shell.execute_reply.started": "2021-10-22T12:54:42.169510Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "#     model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)  #If to train newly\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:54:42.177975Z",
     "iopub.status.busy": "2021-10-22T12:54:42.177451Z",
     "iopub.status.idle": "2021-10-22T12:54:50.705323Z",
     "shell.execute_reply": "2021-10-22T12:54:50.704576Z",
     "shell.execute_reply.started": "2021-10-22T12:54:42.177940Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    # our dataset has two classes only - background and cell\n",
    "num_classes = 2\n",
    "\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "    # move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "    # construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "epoch = 20\n",
    "loss_history = [[],[]]\n",
    "train_n_minibatches = train_dataloader.__len__()\n",
    "validation_n_minibatches = validation_dataloader.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.Training** <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:54:50.706740Z",
     "iopub.status.busy": "2021-10-22T12:54:50.706500Z",
     "iopub.status.idle": "2021-10-22T12:55:08.217400Z",
     "shell.execute_reply": "2021-10-22T12:55:08.215829Z",
     "shell.execute_reply.started": "2021-10-22T12:54:50.706710Z"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "log_idx = 95\n",
    "\n",
    "for e in range(epoch):\n",
    "    for batch_idx , (x ,y) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        x = list(image.to(device) for image in x)\n",
    "        y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "        loss_dict = model(x, y)\n",
    "        \n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_history[0].append(float(loss.detach()))\n",
    "        \n",
    "        if batch_idx % log_idx == 0:\n",
    "            # Printing Log\n",
    "            print(f'LOSS for EPOCH {e+1} BATCH {batch_idx+1}/{train_n_minibatches} TRAIN LOSS : {loss_history[0][-1]}',end = ' ')\n",
    "            with torch.no_grad():\n",
    "                # Calculating loss and accuracy for validation\n",
    "                for _batch_idx_ , (x ,y) in enumerate(validation_dataloader):\n",
    "                    x = list(image.to(device) for image in x)\n",
    "                    y = [{k: v.to(device) for k, v in t.items()} for t in y]\n",
    "                    loss_dict = model(x, y)\n",
    "                    validation_loss = sum(loss for loss in loss_dict.values())\n",
    "                    loss_history[1].append(float(validation_loss.detach()))\n",
    "                                      \n",
    "                print(f'VALIDATION LOSS : {sum(loss_history[1][-1:-validation_n_minibatches-1:-1])/validation_n_minibatches}')\n",
    "\n",
    "    torch.save(model.state_dict(),'masked_rcnn_ss')\n",
    "    #Log for e+1th epoch\n",
    "    print(f'---------------------------------------EPOCH {e+1}-------------------------------------------')\n",
    "    print(f'Loss for EPOCH {e+1}  TRAIN LOSS : {sum(loss_history[0][-1:-train_n_minibatches-1:-1])/train_n_minibatches}')\n",
    "    n_validation_losses = int(train_n_minibatches/log_idx)*validation_n_minibatches\n",
    "    print(f'VALIDATION LOSS for EPOCH {e+1} : {sum(loss_history[1][-1:-1*n_validation_losses-1:-1])/n_validation_losses}',end = '\\n')\n",
    "    print('---------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.Plotting Graphs** <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Plotting Loss vs MiniBatch<a class=\"anchor\" id=\"6.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-22T12:55:08.218493Z",
     "iopub.status.idle": "2021-10-22T12:55:08.218997Z",
     "shell.execute_reply": "2021-10-22T12:55:08.218774Z",
     "shell.execute_reply.started": "2021-10-22T12:55:08.218750Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_loss_history = [[],[]]\n",
    "\n",
    "for i in range(0,len(loss_history[0]),train_n_minibatches):\n",
    "    avg_loss_history[0].append(sum(loss_history[0][i:i+train_n_minibatches])/train_n_minibatches)\n",
    "    \n",
    "for i in range(0,len(loss_history[1]),validation_n_minibatches):\n",
    "    avg_loss_history[1].append(sum(loss_history[1][i:i+validation_n_minibatches])/validation_n_minibatches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-22T12:55:08.220306Z",
     "iopub.status.idle": "2021-10-22T12:55:08.220788Z",
     "shell.execute_reply": "2021-10-22T12:55:08.220573Z",
     "shell.execute_reply.started": "2021-10-22T12:55:08.220550Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=range(len(avg_loss_history[0])),y=avg_loss_history[0])\n",
    "sns.lineplot(x=range(len(avg_loss_history[1])),y=avg_loss_history[1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Plotting Loss vs Epoch<a class=\"anchor\" id=\"6.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-22T12:55:08.222580Z",
     "iopub.status.idle": "2021-10-22T12:55:08.222992Z",
     "shell.execute_reply": "2021-10-22T12:55:08.222787Z",
     "shell.execute_reply.started": "2021-10-22T12:55:08.222765Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting Loss per epoch\n",
    "loss_per_epoch = [[],[]]\n",
    "for i in range(epoch):\n",
    "    temp = 0\n",
    "    for j in loss_history[0][i*train_n_minibatches:(i+1)*train_n_minibatches]:\n",
    "        temp = temp + j\n",
    "    loss_per_epoch[0].append(temp/train_n_minibatches)\n",
    "    temp = 0\n",
    "    for j in loss_history[1][i*n_validation_losses:(i+1)*n_validation_losses]:\n",
    "        temp = temp + j\n",
    "    loss_per_epoch[1].append(temp/n_validation_losses)    \n",
    "\n",
    "sns.lineplot(x=range(len(loss_per_epoch[0])),y=loss_per_epoch[0])\n",
    "sns.lineplot(x=range(len(loss_per_epoch[1])),y=loss_per_epoch[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7.Loading and Testing**<a class=\"anchor\" id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-22T12:55:08.224363Z",
     "iopub.status.idle": "2021-10-22T12:55:08.224765Z",
     "shell.execute_reply": "2021-10-22T12:55:08.224571Z",
     "shell.execute_reply.started": "2021-10-22T12:55:08.224549Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_model_instance_segmentation(num_classes)\n",
    "    # move model to the right device\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('masked_rcnn_ss', map_location='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-22T12:55:08.226146Z",
     "iopub.status.idle": "2021-10-22T12:55:08.226561Z",
     "shell.execute_reply": "2021-10-22T12:55:08.226364Z",
     "shell.execute_reply.started": "2021-10-22T12:55:08.226342Z"
    }
   },
   "outputs": [],
   "source": [
    "test_model(model, validation_dataloader,n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8.Predictions**<a class=\"anchor\" id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-22T12:55:08.229847Z",
     "iopub.status.idle": "2021-10-22T12:55:08.230260Z",
     "shell.execute_reply": "2021-10-22T12:55:08.230064Z",
     "shell.execute_reply.started": "2021-10-22T12:55:08.230042Z"
    }
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root,transforms = None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.img_name = []\n",
    "        for i in os.listdir(root+'test/'):\n",
    "            self.img_name.append(i[:-4])\n",
    "        self.w , self.h = 520 , 704\n",
    "\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.root+'test/'+self.img_name[idx]+'.png').convert(\"RGB\")\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image , self.img_name[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-22T12:55:08.231523Z",
     "iopub.status.idle": "2021-10-22T12:55:08.232241Z",
     "shell.execute_reply": "2021-10-22T12:55:08.232017Z",
     "shell.execute_reply.started": "2021-10-22T12:55:08.231992Z"
    }
   },
   "outputs": [],
   "source": [
    "td = TestDataset(root, transforms=get_transform(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-22T12:55:08.233460Z",
     "iopub.status.idle": "2021-10-22T12:55:08.234088Z",
     "shell.execute_reply": "2021-10-22T12:55:08.233871Z",
     "shell.execute_reply.started": "2021-10-22T12:55:08.233847Z"
    }
   },
   "outputs": [],
   "source": [
    "DROP_OVERLAPPING = False\n",
    "\n",
    "submission = []\n",
    "counter = 0\n",
    "\n",
    "min_precision = 0.5\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for img,img_name in td:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        result = model([img.to(device)])[0]\n",
    "        \n",
    "    if len(result[\"masks\"]) != 0:\n",
    "        previous_masks = []\n",
    "        for j, m in enumerate(result[\"masks\"]):\n",
    "            original_mask = result[\"masks\"][j][0].cpu().numpy()\n",
    "            if DROP_OVERLAPPING and does_overlap(original_mask, previous_masks):\n",
    "                continue\n",
    "            else:\n",
    "                original_mask = remove_overlapping_pixels(original_mask, previous_masks)\n",
    "                previous_masks.append(original_mask)\n",
    "                rle = rle_encoding(original_mask > min_precision)\n",
    "                submission.append([img_name, rle])\n",
    "    else:\n",
    "        submission.append([img_name, \"\"])\n",
    "\n",
    "df_sub = pd.DataFrame(submission, columns=['id', 'predicted'])\n",
    "df_sub.to_csv(\"submission.csv\", index=False)\n",
    "df_sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
